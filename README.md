## üé≤ INSTALA√á√ÉO DO HADOOP - SISTEMA OPERACIONAL UBUNTU 

O objetivo deste material √© auxiliar na instala√ß√£o do framework Hadoop!

### üìå Passo 1: Pr√© Requisito - JAVA

O primeiro passo √© instalar o JAVA na sua m√°quina: M√°quina Virtual Java.  

```bash
# Primeiro abra o terminal com o atalho ( CTRL + ALT + T )

$ sudo add-apt-repository ppa:webupd8team/java

$ sudo apt-get update

$ sudo apt-get install oracle-java8-installer

# Agora aplique o comando no terminal para saber qual √© a vers√£o do java instalado!

$ java -version

```

### üìå Passo 2: Pr√© Requisito - SSH



```bash
# Com o terminal aberto, aplique o seguinte comando:

$ sudo apt-get install openssh-server

$ sudo service ssh start

# Para a configura√ß√£o do SSH voc√™ poder√° seguir os passos deste artigo: https://sempreupdate.com.br/como-ativar-e-instalar-o-ssh-no-ubuntu/

```

### üìå Passo 3: Pr√© Requisito - USU√ÅRIO

Para o desenvolvimento da instala√ß√£o de acordo com este tutorial, voc√™ deve criar um usu√°rio exclusivo para trabalhar com o Hadoop.

```bash
# Usu√°rio: hduser
# Senha: 
```

### üìå Passo 4: Colocando o USU√ÅRIO no grupo Hadoop

Essa etapa √© opcional! 

```bash
$ sudo addgroup hadoop

$ sudo adduser --ingroup hadoop hduser
```

> üí¨ Vale lembrar que o Hadoop utiliza SSH para gerenciar os n√≥s! 
> üí¨ Mesmo para localhost, √© indicado configurar o acesso ao localhost para o usu√°rio que foi criado: hduser sem senha.
> üí¨ Vamos considerar que o SSH j√° est√° executando na sua m√°quina! 


### üìå Passo 5: CONECTANDO USU√ÅRIO E GERANDO CHAVE SSH

Um passo muito importante ser√° aplicado agora, pois ser√° conectado com o usu√°rio hduser, gerando uma chave SSH para esse mesmo usu√°rio com a senha vazia. 

```bash
# Conectando usu√°rio
$ su - hduser

# Gerando chave SSH para o usu√°rio hduser
$ ssh-keygen - t rsa -P ""
```

### üìå Passo 6: Habilitar o SSH com a chave

Este passo tem como objetivo habilitar o SSH para acessar a m√°quina local com a chave recentemente criada.

```bash
$ cat $HOME/.ssh/id_rsa.pub >> $HOME/.ssh/authorized_keys
```

### üìå Passo 7: Testando a conex√£o com a m√°quina 

Vamos realizar o teste com a conex√£o para a m√°quina local do usu√°rio hduser!

```bash
$ ssh localhost
```
> üí¨ Caso o sistema n√£o solicite a senha quer dizer que deu tudo CERTO! 
> üí¨ Caso o sistema solicite a senha √© recomendado que voc√™ fa√ßa todos os passos novamente!

### üìå Passo 8: INSTALA√á√ÉO DO RECURSO 'ABRIR COMO ADMINISTRADOR'

As vezes precisamos abrir pastas ou editar arquivos e n√£o temos as devidas permiss√µes para fazer a tarefa. Nessa situa√ß√£o, voc√™ precisa abrir um terminal e executar o Nautilus como root, o que n√£o √© muito produtivo. Para realizar a instala√ß√£o aplique os seguintes comandos no terminal!

```bash
# Instalar o recurso
$ sudo apt install nautilus-admin

# Reiniciar o recurso instalado
$ nautilus -q

# Fonte do artigo: encurtador.com.br/mnuI6
```
### üìå Passo 9: DESABILITAR O IPV6

Abra o arquivo com um editor de texto com o recurso de administrador e aplique o seguinte comando no fim do arquivo:


```bash
# Endere√ßo do arquivo: /etc/sysctl.conf

################################# disable ipv6

$ net.ipv6.conf.all.disable_ipv6 = 1

$ net.ipv6.conf.default.disable_ipv6 = 1

$ net.ipv6.conf.lo.disable_ipv6 = 1
```

Logo ap√≥s, reinicie a m√°quina!

### üìå Passo 10: VERIFICANDO SE O IPV6 EST√Å DESABILITADO

```bash
$ cat /proc/sys/net/ipv6/conf/all/disable_ipv6
```
> üí¨ Caso o comando retorne 0 (zero), o ipv6 est√° habilitado! 
> üí¨ Se retornar 1 (um), o ipv6 est√° desabilitado! 

Lembrando que o nosso objetivo √© que o sistema retorne 1!


### üìå Passo 10: DOWNLOAD DO HADOOP

Voc√™ poder√° baixar o arquivo pelo o link
```bash
# Link para download: https://hadoop.apache.org/release/2.7.3.html
```

> üí¨ SUGEST√ÉO: Descompactar no diret√≥rio /usr/local/

```bash
$ cd /usr/local

$ sudo tar xzf hadoop-2.7.3.tar.gz

# Este comando est√° trocando o nome do arquivo original para apenas 'hadoop' para simplificar
$ sudo mv hadoop-2.7.3 hadoop

# J√° este comando estamos permitindo permiss√£o a essa pasta recentimente criada!
$ sudo chown -R hduser:hadoop hadoop
```

### üìå Passo 11: CRIA√á√ÉO DAS VARIAVEIS DE AMBIENTE

Para isso √© necess√°rio editar o arquivo .bashrc para o usu√°rio hduser tanto para o HADOOP e JAVA. No arquivo adicione os seguintes comandos:

```bash
# Set Hadoop-relatec environment variables
$ export HADOOP_HOME=/usr/local/hadoop

# Set JAVA_HOME
$ export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
```

Vale lembrar que na variavel HADOOP_HOME e JAVA_HOME voc√™ precisa apontar no local que est√° na sua m√°quina!

### üìå Passo 12: CONFIGURANDO O HADOOP

O primeiro passo agora √© criar um diret√≥rio para armazenamento de dados tempor√°rios do HADOOP, e para isso vamos criar no endere√ßo /usr/local/tmp


```bash
$ sudo mkdir -p /usr/local/hadoop/tmp
```
Esse diret√≥rio vai ser utilizado posteriormente!

Agora vamos atribuir permiss√µes ao novo diret√≥rio:


```bash
$ sudo chown hduser:hadoop /usr/local/hadoop/tmp
$ sudo chmod +x /usr/local/hadoop/tmp
```

Agora vamos alterar o arquivo core-site.xml que est√° no endere√ßo /usr/local/hadoop/etc/hadoop/core-site.xml e aplique o seguinte comando ENTRE as tags <configuration> </configuration>

Lembrando que voc√™ deve clicar com o bot√£o direitor do mouse e ir na op√ß√£o 'ABRIR COMO ADMINISTRADOR'

```bash
  <configuration>
    <property> 
      <name>/usr/local/hadoop/tmp</name>
      <value>/app/hadoop/tmp</value>
    </property>

    <property>
      <name>fs.default.name</name>
      <value>hdfs://localhost:54310</value>
    </property>
  </configuration>
```

Logo ap√≥s, vamos alterar o arquivo mapred-site.xml que est√° no endere√ßo /usr/local/hadoop/etc/hadoop/mapred-site.xml.template! N√£o esque√ßa que voc√™ deve colocar o seguinte c√≥digo ENTRE as tags <configuration> </configuration>

Lembrando que voc√™ deve clicar com o bot√£o direitor do mouse e ir na op√ß√£o 'ABRIR COMO ADMINISTRADOR'


```bash
  <configuration>
    <property>
      <name> mapred.job.tracker </name>
      <value> localhost:54311 </value>
    </property>
  </configuration>
```

Agora, vamos alterar o arquivo hdfs-site.xml que est√° no endere√ßo usr/local/hadoop/etc/hadoop/hdfs-site.xml! N√£o esque√ßa que voc√™ deve colocar o seguinte c√≥digo ENTRE as tags <configuration> 
  
  Lembrando que voc√™ deve clicar com o bot√£o direitor do mouse e ir na op√ß√£o 'ABRIR COMO ADMINISTRADOR'

  
```bash
  <configuration>
    <property>
      <name> dfs.replication </name>
      <value> 1 </value>
    </property>
  </configuration>
```

### üìå Passo 13: FORMANDO O HDFS

Para formatar o sistema de arquivos distribuido - HDFS, voc√™ dever√° aplicar o seguinte comando no seu terminal!

```bash
/usr/local/hadoo·πï/bin/hadoop/namenode -format
```

A sa√≠da do comando deve ser a seguinte:

```bash
DEPRECATED: Use of this script to execute hdfs command is deprecated.
Instead use the hdfs command for it.

21/04/02 18:15:16 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = gabriel-tuk/127.0.1.1
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 2.7.3
```

### üìå Passo 14: INICIANDO OS SERVI√áOS HADOOP


```bash
/usr/local/hadoo·πï/bin/hadoop/sbin/star-all.sh
```

A sa√≠da deve ser a seguinte:

```bash
Starting namenodes on [localhost]
localhost: starting namenode, logging to /usr/local/hadoop/logs/hadoop-root-namenode-gabriel-tuk.out
localhost: starting datanode, logging to /usr/local/hadoop/logs/hadoop-root-datanode-gabriel-tuk.out
Starting secondary namenodes [0.0.0.0]
The authenticity of host '0.0.0.0 (0.0.0.0)' can't be established.
ECDSA key fingerprint is SHA256:zCoTX0sbPIug7X/QC6fW54qOMuV+WNtKJNrKWfomUck.
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
0.0.0.0: Warning: Permanently added '0.0.0.0' (ECDSA) to the list of known hosts.
0.0.0.0: starting secondarynamenode, logging to /usr/local/hadoop/logs/hadoop-root-secondarynamenode-gabriel-tuk.out
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.3.jar) to method sun.security.krb5.Config.getInstance()
WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
starting yarn daemons
starting resourcemanager, logging to /usr/local/hadoop/logs/yarn-root-resourcemanager-gabriel-tuk.out
localhost: starting nodemanager, logging to /usr/local/hadoop/logs/yarn-root-nodemanager-gabriel-tuk.out
```

